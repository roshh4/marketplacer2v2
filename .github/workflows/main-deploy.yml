name: Build and Deploy - Main Branch

on:
  push:
    branches: [ main ]
  workflow_dispatch:

env:
  AZURE_RESOURCE_GROUP: rg-marketplace-dev
  AZURE_LOCATION: southeastasia

jobs:
  build-and-deploy-backend:
    runs-on: ubuntu-latest
    outputs:
      backend-url: ${{ steps.terraform-output.outputs.backend_url }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3
      
    - name: Login to Docker Hub
      uses: docker/login-action@v3
      with:
        username: ${{ secrets.DOCKERHUB_USERNAME }}
        password: ${{ secrets.DOCKERHUB_TOKEN }}
        
    - name: Generate version tag
      id: version
      run: |
        VERSION=$(date +%Y%m%d)-$(echo ${{ github.sha }} | cut -c1-7)
        echo "version=v${VERSION}" >> $GITHUB_OUTPUT
        echo "Generated version: v${VERSION}"
        
    - name: Build and push backend with version tag
      uses: docker/build-push-action@v5
      with:
        context: ./backend
        file: ./backend/Dockerfile
        push: true
        tags: |
          roshh4/marketplace-backend-alpine-amd64:latest
          roshh4/marketplace-backend-alpine-amd64:${{ steps.version.outputs.version }}
        platforms: linux/amd64
        
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.6.0
        terraform_wrapper: false
        
    - name: Azure Login
      uses: azure/login@v1
      with:
        creds: |
          {
            "clientId": "${{ secrets.AZURE_CLIENT_ID }}",
            "clientSecret": "${{ secrets.AZURE_CLIENT_SECRET }}",
            "subscriptionId": "${{ secrets.AZURE_SUBSCRIPTION_ID }}",
            "tenantId": "${{ secrets.AZURE_TENANT_ID }}"
          }
          
    - name: Install kubectl
      uses: azure/setup-kubectl@v3
      with:
        version: 'v1.30.0'
          
    - name: Verify clean environment
      run: |
        echo "Current Azure account:"
        az account show --query "{subscriptionId:id, name:name, user:user.name}" --output table
        
        echo "Current resources:"
        az resource list --query "[].{name:name, type:type, resourceGroup:resourceGroup}" --output table
          
    - name: Terraform Init
      run: |
        cd terraform
        terraform init
        
    - name: Import existing resources (if they exist)
      run: |
        cd terraform
        
        # Try to import existing resources, ignore errors if they don't exist
        terraform import -var="db_admin_password=${{ secrets.DB_PASSWORD }}" -var="container_image_tag=${{ steps.version.outputs.version }}" -var="storage_account_name=${{ secrets.AZURE_STORAGE_ACCOUNT_NAME }}" azurerm_resource_group.marketplace "/subscriptions/${{ secrets.AZURE_SUBSCRIPTION_ID }}/resourceGroups/rg-marketplace-dev" || true
        
        # Import existing PostgreSQL resources
        terraform import -var="db_admin_password=${{ secrets.DB_PASSWORD }}" -var="container_image_tag=${{ steps.version.outputs.version }}" -var="storage_account_name=${{ secrets.AZURE_STORAGE_ACCOUNT_NAME }}" azurerm_postgresql_flexible_server.marketplace "/subscriptions/${{ secrets.AZURE_SUBSCRIPTION_ID }}/resourceGroups/rg-marketplace-dev/providers/Microsoft.DBforPostgreSQL/flexibleServers/psql-marketplace-dev" || true
        
        terraform import -var="db_admin_password=${{ secrets.DB_PASSWORD }}" -var="container_image_tag=${{ steps.version.outputs.version }}" -var="storage_account_name=${{ secrets.AZURE_STORAGE_ACCOUNT_NAME }}" azurerm_postgresql_flexible_server_database.marketplace "/subscriptions/${{ secrets.AZURE_SUBSCRIPTION_ID }}/resourceGroups/rg-marketplace-dev/providers/Microsoft.DBforPostgreSQL/flexibleServers/psql-marketplace-dev/databases/marketplace" || true
        
        terraform import -var="db_admin_password=${{ secrets.DB_PASSWORD }}" -var="container_image_tag=${{ steps.version.outputs.version }}" -var="storage_account_name=${{ secrets.AZURE_STORAGE_ACCOUNT_NAME }}" azurerm_postgresql_flexible_server_firewall_rule.azure_services "/subscriptions/${{ secrets.AZURE_SUBSCRIPTION_ID }}/resourceGroups/rg-marketplace-dev/providers/Microsoft.DBforPostgreSQL/flexibleServers/psql-marketplace-dev/firewallRules/AllowAzureServices" || true
        
        # Import existing storage resources
        terraform import -var="db_admin_password=${{ secrets.DB_PASSWORD }}" -var="container_image_tag=${{ steps.version.outputs.version }}" -var="storage_account_name=${{ secrets.AZURE_STORAGE_ACCOUNT_NAME }}" azurerm_storage_account.marketplace_storage "/subscriptions/${{ secrets.AZURE_SUBSCRIPTION_ID }}/resourceGroups/rg-marketplace-dev/providers/Microsoft.Storage/storageAccounts/${{ secrets.AZURE_STORAGE_ACCOUNT_NAME }}" || true

        terraform import -var="db_admin_password=${{ secrets.DB_PASSWORD }}" -var="container_image_tag=${{ steps.version.outputs.version }}" -var="storage_account_name=${{ secrets.AZURE_STORAGE_ACCOUNT_NAME }}" azurerm_storage_container.images "https://${{ secrets.AZURE_STORAGE_ACCOUNT_NAME }}.blob.core.windows.net/images" || true
        
        # Import existing AKS cluster
        terraform import -var="db_admin_password=${{ secrets.DB_PASSWORD }}" -var="container_image_tag=${{ steps.version.outputs.version }}" -var="storage_account_name=${{ secrets.AZURE_STORAGE_ACCOUNT_NAME }}" azurerm_kubernetes_cluster.marketplace "/subscriptions/${{ secrets.AZURE_SUBSCRIPTION_ID }}/resourceGroups/rg-marketplace-dev/providers/Microsoft.ContainerService/managedClusters/aks-marketplace-dev" || true
        
    - name: Terraform Plan
      run: |
        cd terraform
        terraform plan \
          -var="db_admin_password=${{ secrets.DB_PASSWORD }}" \
          -var="container_image_tag=${{ steps.version.outputs.version }}" \
          -var="storage_account_name=${{ secrets.AZURE_STORAGE_ACCOUNT_NAME }}"
          
    - name: Terraform Apply
      run: |
        cd terraform
        terraform apply -auto-approve \
          -var="db_admin_password=${{ secrets.DB_PASSWORD }}" \
          -var="container_image_tag=${{ steps.version.outputs.version }}" \
          -var="storage_account_name=${{ secrets.AZURE_STORAGE_ACCOUNT_NAME }}"
          
    - name: Deploy Kubernetes resources
      run: |
        cd terraform
        # Get AKS credentials
        RESOURCE_GROUP=$(terraform output -raw resource_group_name)
        CLUSTER_NAME=$(terraform output -raw aks_cluster_name)
        echo "Resource Group: ${RESOURCE_GROUP}"
        echo "Cluster Name: ${CLUSTER_NAME}"
        
        # Get AKS credentials
        az aks get-credentials --resource-group ${RESOURCE_GROUP} --name ${CLUSTER_NAME} --overwrite-existing
        
        # Install NGINX Ingress Controller
        echo "Installing NGINX Ingress Controller..."
        kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.2/deploy/static/provider/cloud/deploy.yaml
        
        # Wait for NGINX Ingress to be ready
        kubectl wait --namespace ingress-nginx \
          --for=condition=ready pod \
          --selector=app.kubernetes.io/component=controller \
          --timeout=300s
        # Install cert-manager (for Let's Encrypt)
        echo "Installing cert-manager..."
        kubectl apply -f https://github.com/cert-manager/cert-manager/releases/download/v1.15.3/cert-manager.yaml
        kubectl -n cert-manager rollout status deploy/cert-manager --timeout=300s
        kubectl -n cert-manager rollout status deploy/cert-manager-webhook --timeout=300s
        kubectl -n cert-manager rollout status deploy/cert-manager-cainjector --timeout=300s

        # Get NGINX Ingress external IP (for nip.io host)
        echo "Waiting for NGINX Ingress external IP..."
        for i in {1..30}; do
          EXTERNAL_IP=$(kubectl get service ingress-nginx-controller -n ingress-nginx -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo "")
          if [ ! -z "$EXTERNAL_IP" ] && [ "$EXTERNAL_IP" != "null" ]; then
            echo "NGINX Ingress external IP: $EXTERNAL_IP"
            break
          fi
          echo "Attempt $i: Waiting for NGINX Ingress external IP..."
          sleep 10
        done

        if [ -z "$EXTERNAL_IP" ] || [ "$EXTERNAL_IP" == "null" ]; then
          echo "Failed to get NGINX Ingress external IP after 5 minutes"
          exit 1
        fi

        # Configure nip.io hostname in ingress
        NIP_HOST="${EXTERNAL_IP}.nip.io"
        echo "Configuring ingress host to: $NIP_HOST"
        cd ..
        # Update both tls.hosts and rules.host in place
        sed -i "s/^\(\s*- hosts:\s*\n\s*-\s*\).*/\1${NIP_HOST}/" k8s/ingress.yaml
        sed -i "s/^\(\s*- host:\s*\).*/\1${NIP_HOST}/" k8s/ingress.yaml

        # Ensure target namespace exists
        kubectl get ns marketplace >/dev/null 2>&1 || kubectl create ns marketplace

        # Create/Update application secrets from GitHub Secrets
        echo "Applying marketplace-secrets from GitHub Secrets..."
        kubectl create secret generic marketplace-secrets \
          -n marketplace \
          --from-literal=db-password="${{ secrets.DB_PASSWORD }}" \
          --from-literal=storage-connection-string="${{ secrets.AZURE_STORAGE_CONNECTION_STRING }}" \
          --from-literal=content-safety-key="${{ secrets.CONTENT_SAFETY_KEY }}" \
          --from-literal=content-safety-endpoint="${{ secrets.CONTENT_SAFETY_ENDPOINT }}" \
          --from-literal=gemini-api-key="${{ secrets.GEMINI_API_KEY }}" \
          --dry-run=client -o yaml | kubectl apply -f -

        # Apply cert issuer and ingress (cert-manager will create Certificate + Secret)
        # Replace email placeholder with GitHub secret
        sed -i "s/CERT_MANAGER_EMAIL_PLACEHOLDER/${{ secrets.CERT_MANAGER_EMAIL }}/" k8s/cert-issuer.yaml
        kubectl apply -f k8s/cert-issuer.yaml
        kubectl apply -n marketplace -f k8s/ingress.yaml
        
        # Wait for certificate to be ready (up to 5 minutes)
        echo "Waiting for Let's Encrypt certificate to be issued..."
        for i in {1..30}; do
          if kubectl get certificate marketplace-tls-cert -n marketplace -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}' | grep -q "True"; then
            echo "✅ Certificate is ready!"
            break
          fi
          echo "Attempt $i: Certificate not ready yet..."
          sleep 10
        done

        # Deploy the rest of Kubernetes resources
        kubectl apply -f k8s/
        
        # Scale down to 1 to avoid CPU starvation on single-node cluster
        kubectl scale deployment/marketplace-backend -n marketplace --replicas=1 || true

        # Update the deployment with the new image tag
        kubectl set image deployment/marketplace-backend marketplace-backend=roshh4/marketplace-backend-alpine-amd64:${{ steps.version.outputs.version }} -n marketplace
        
        # Wait for rollout to complete (longer timeout) and dump diagnostics if it fails
        set +e
        kubectl rollout status deployment/marketplace-backend -n marketplace --timeout=600s
        STATUS=$?
        set -e
        if [ $STATUS -ne 0 ]; then
          echo "Deployment rollout failed; collecting diagnostics..."
          kubectl get pods -n marketplace -o wide
          kubectl describe deployment marketplace-backend -n marketplace || true
          kubectl describe pods -n marketplace | sed -n '1,200p' || true
          kubectl logs -n marketplace deploy/marketplace-backend --tail=200 || true
          exit 1
        fi
        
        # Scale back up to 2 replicas once stable
        kubectl scale deployment/marketplace-backend -n marketplace --replicas=2 || true

        # Verify deployment
        kubectl get pods -n marketplace
        kubectl get services -n marketplace
        
        echo "✅ Application deployed to AKS successfully!"
        
    - name: Get Backend URL from LoadBalancer
      id: terraform-output
      run: |
        cd terraform
        # Get AKS credentials first
        RESOURCE_GROUP=$(terraform output -raw resource_group_name)
        CLUSTER_NAME=$(terraform output -raw aks_cluster_name)
        az aks get-credentials --resource-group ${RESOURCE_GROUP} --name ${CLUSTER_NAME} --overwrite-existing
        
        # Wait for NGINX Ingress LoadBalancer to get external IP (up to 5 minutes)
        echo "Waiting for NGINX Ingress external IP..."
        for i in {1..30}; do
          EXTERNAL_IP=$(kubectl get service ingress-nginx-controller -n ingress-nginx -o jsonpath='{.status.loadBalancer.ingress[0].ip}' 2>/dev/null || echo "")
          if [ ! -z "$EXTERNAL_IP" ] && [ "$EXTERNAL_IP" != "null" ]; then
            echo "NGINX Ingress external IP: $EXTERNAL_IP"
            NIP_HOST="${EXTERNAL_IP}.nip.io"
            BACKEND_URL="https://${NIP_HOST}"
            echo "backend_url=${BACKEND_URL}" >> $GITHUB_OUTPUT
            echo "Backend URL: ${BACKEND_URL}"
            break
          fi
          echo "Attempt $i: Waiting for NGINX Ingress external IP..."
          sleep 10
        done
        
        if [ -z "$EXTERNAL_IP" ] || [ "$EXTERNAL_IP" == "null" ]; then
          echo "Failed to get NGINX Ingress external IP after 5 minutes"
          exit 1
        fi
        
    - name: Verify Backend Health
      run: |
        BACKEND_URL="${{ steps.terraform-output.outputs.backend_url }}"
        echo "Testing backend health at: ${BACKEND_URL}/health"
        
        # Wait up to 2 minutes for backend to be ready
        for i in {1..12}; do
          if curl -k -f "${BACKEND_URL}/health" >/dev/null 2>&1; then
            echo "✅ Backend is healthy and accessible!"
            break
          fi
          echo "Attempt $i: Backend not ready yet..."
          sleep 10
        done
        
        # Final health check
        echo "Final health check:"
        curl -k -v "${BACKEND_URL}/health" || echo "⚠️ Backend health check failed, but continuing deployment"

  build-and-deploy-frontend:
    runs-on: ubuntu-latest
    needs: build-and-deploy-backend
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: './frontend/package-lock.json'
        
    - name: Install dependencies
      run: |
        cd frontend
        npm ci
        
    - name: Build frontend with backend URL
      run: |
        cd frontend
        echo "Building frontend with backend URL: ${{ needs.build-and-deploy-backend.outputs.backend-url }}"
        echo "VITE_API_URL=${{ needs.build-and-deploy-backend.outputs.backend-url }}" > .env.production
        echo "VITE_NODE_ENV=production" >> .env.production
        cat .env.production
        npm run build
        
    - name: Deploy to Azure Static Web Apps
      uses: Azure/static-web-apps-deploy@v1
      with:
        azure_static_web_apps_api_token: ${{ secrets.AZURE_STATIC_WEB_APPS_API_TOKEN }}
        repo_token: ${{ secrets.GITHUB_TOKEN }}
        action: "upload"
        app_location: "./frontend"
        output_location: "dist"
        
    - name: Frontend deployment status
      run: |
        if [ -n "${{ secrets.AZURE_STATIC_WEB_APPS_API_TOKEN }}" ]; then
          echo "✅ Frontend deployed to Static Web App"
          echo "Frontend URL: https://ashy-coast-049069600.2.azurestaticapps.net"
        else
          echo "⚠️ Frontend deployment skipped - AZURE_STATIC_WEB_APPS_API_TOKEN not set"
          echo "Add the Static Web App deployment token to GitHub secrets"
        fi